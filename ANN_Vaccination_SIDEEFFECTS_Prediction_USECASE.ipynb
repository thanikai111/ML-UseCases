{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUsiness Scenario: Drug Vaccination Trial \n",
    "    Vaccination given: 13 to 100 years\n",
    "    People who are between 13 to 64 years no side effects\n",
    "    65 and above came across some side affects\n",
    "    \n",
    "    MOdel in ANN which has details of peoples with different ages and whether they had side effect or notA\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np#input can be provided to Keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will create a dataset\n",
    "train_sample=[]# Will have list of peoples who have been provided with vaccination or not\n",
    "train_lablel=[]#Vaccination provide has any side affect or not\n",
    "\n",
    "for i in range(1000):\n",
    "    age_young=randint(13,64)\n",
    "    train_sample.append(age_young)\n",
    "    train_lablel.append(0)\n",
    "    \n",
    "    age_older=randint(65,100)\n",
    "    train_sample.append(age_older)\n",
    "    train_lablel.append(1)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 82, 39, 95, 44, 81, 60, 80, 64, 81, 31, 73, 43, 75, 64, 75, 21, 74, 30, 91, 13, 77, 30, 83, 53, 87, 33, 96, 20, 86, 14, 76, 33, 92, 44, 79, 45, 95, 27, 67, 60, 69, 20, 92, 54, 78, 48, 96, 38, 76, 45, 70, 61, 89, 26, 78, 32, 85, 61, 96, 60, 98, 49, 69, 25, 77, 32, 98, 38, 94, 39, 81, 27, 75, 42, 66, 54, 71, 36, 84, 39, 71, 20, 67, 63, 71, 60, 95, 24, 96, 53, 68, 15, 87, 47, 90, 60, 97, 58, 73, 28, 77, 56, 89, 46, 91, 43, 76, 54, 90, 61, 73, 36, 86, 54, 95, 39, 89, 58, 66, 27, 100, 31, 95, 39, 82, 52, 75, 48, 65, 29, 75, 44, 85, 63, 93, 31, 66, 57, 66, 52, 79, 16, 66, 29, 72, 61, 73, 25, 65, 54, 82, 44, 77, 41, 90, 33, 67, 14, 74, 44, 96, 45, 77, 58, 90, 60, 82, 57, 79, 62, 69, 46, 97, 48, 84, 44, 65, 63, 84, 55, 65, 61, 84, 23, 72, 35, 76, 45, 73, 38, 94, 32, 90, 27, 78, 51, 100, 63, 74, 22, 72, 23, 99, 51, 68, 50, 76, 30, 91, 46, 98, 34, 75, 24, 74, 55, 99, 52, 81, 38, 72, 14, 90, 60, 67, 33, 79, 26, 73, 61, 66, 19, 94, 40, 84, 14, 67, 16, 74, 43, 72, 18, 78, 21, 99, 33, 84, 38, 80, 56, 82, 38, 90, 30, 76, 15, 82, 52, 100, 15, 67, 34, 82, 57, 76, 18, 80, 22, 90, 61, 76, 28, 82, 13, 77, 33, 99, 62, 91, 62, 97, 33, 99, 60, 68, 44, 65, 32, 75, 33, 74, 56, 70, 45, 91, 21, 73, 24, 93, 51, 98, 18, 68, 32, 73, 22, 69, 41, 67, 40, 91, 30, 77, 28, 89, 59, 77, 53, 93, 18, 72, 26, 70, 19, 70, 22, 98, 22, 91, 36, 65, 41, 79, 27, 100, 53, 86, 38, 90, 59, 77, 15, 100, 36, 92, 56, 79, 44, 86, 56, 89, 33, 84, 51, 68, 51, 91, 45, 77, 49, 76, 40, 71, 14, 89, 38, 82, 24, 95, 54, 98, 16, 70, 19, 78, 26, 96, 43, 66, 47, 74, 53, 70, 24, 67, 50, 77, 14, 66, 17, 68, 64, 77, 38, 73, 25, 72, 44, 81, 34, 81, 43, 84, 38, 71, 62, 80, 60, 99, 28, 82, 58, 76, 36, 95, 46, 75, 18, 76, 45, 88, 44, 68, 37, 88, 25, 73, 51, 68, 35, 73, 59, 71, 57, 85, 60, 71, 34, 71, 53, 80, 62, 91, 46, 80, 47, 84, 64, 66, 35, 94, 45, 69, 21, 100, 42, 88, 40, 75, 35, 97, 54, 92, 56, 67, 32, 97, 23, 91, 43, 99, 45, 84, 33, 74, 64, 92, 35, 86, 59, 88, 48, 100, 33, 96, 42, 74, 27, 69, 27, 91, 17, 67, 59, 83, 27, 96, 23, 92, 39, 66, 21, 93, 42, 70, 23, 83, 25, 100, 56, 75, 15, 85, 16, 82, 14, 83, 39, 75, 52, 89, 46, 77, 33, 96, 39, 92, 62, 95, 19, 92, 46, 73, 64, 80, 60, 66, 13, 83, 39, 79, 53, 97, 56, 97, 41, 80, 16, 85, 57, 73, 36, 87, 60, 76, 30, 98, 37, 91, 41, 69, 55, 77, 38, 68, 51, 95, 34, 83, 17, 99, 51, 77, 18, 90, 25, 99, 48, 71, 51, 85, 60, 84, 22, 82, 57, 96, 18, 100, 38, 68, 23, 91, 59, 95, 17, 70, 30, 92, 60, 94, 21, 96, 57, 99, 54, 76, 22, 72, 18, 72, 16, 78, 32, 69, 49, 93, 34, 68, 45, 70, 41, 85, 55, 70, 39, 89, 35, 70, 32, 91, 35, 95, 38, 88, 29, 66, 59, 92, 63, 99, 63, 83, 44, 73, 62, 81, 49, 99, 15, 80, 14, 89, 46, 100, 49, 69, 46, 89, 39, 84, 64, 65, 49, 88, 25, 76, 19, 75, 27, 88, 55, 99, 23, 82, 31, 66, 50, 85, 55, 77, 13, 90, 18, 95, 26, 81, 13, 70, 18, 73, 34, 87, 14, 75, 29, 93, 33, 67, 64, 74, 18, 92, 20, 68, 26, 86, 20, 71, 25, 82, 38, 81, 54, 80, 21, 73, 14, 71, 34, 71, 63, 83, 41, 67, 42, 99, 27, 69, 51, 80, 47, 75, 46, 70, 47, 83, 49, 77, 14, 92, 28, 71, 39, 80, 51, 90, 47, 96, 55, 69, 60, 71, 57, 68, 56, 73, 26, 79, 58, 92, 51, 93, 24, 99, 60, 94, 51, 83, 53, 88, 54, 99, 13, 68, 36, 94, 26, 72, 46, 98, 34, 90, 46, 71, 40, 96, 48, 100, 28, 69, 49, 75, 16, 83, 38, 69, 41, 86, 29, 78, 24, 81, 16, 71, 23, 68, 39, 95, 18, 88, 30, 99, 56, 81, 43, 74, 28, 78, 46, 73, 52, 65, 38, 82, 60, 70, 40, 67, 33, 85, 26, 92, 35, 67, 58, 96, 23, 77, 26, 91, 24, 66, 56, 99, 14, 90, 16, 88, 55, 95, 14, 68, 24, 73, 45, 84, 28, 83, 44, 82, 30, 68, 34, 65, 29, 83, 21, 97, 15, 85, 30, 72, 23, 83, 50, 91, 14, 79, 20, 73, 15, 74, 51, 70, 39, 87, 46, 100, 25, 82, 57, 84, 16, 90, 35, 72, 41, 96, 45, 74, 22, 88, 25, 78, 26, 99, 40, 95, 44, 100, 31, 96, 63, 67, 16, 75, 52, 86, 33, 93, 26, 84, 13, 92, 48, 73, 57, 85, 39, 73, 13, 85, 35, 75, 47, 65, 20, 80, 22, 95, 42, 86, 31, 89, 50, 66, 32, 75, 40, 89, 34, 80, 36, 90, 64, 92, 39, 72, 46, 92, 59, 77, 24, 67, 28, 96, 50, 84, 22, 67, 20, 66, 45, 68, 37, 72, 28, 72, 51, 75, 46, 79, 20, 87, 17, 83, 30, 98, 39, 70, 22, 68, 55, 84, 34, 71, 21, 86, 18, 88, 27, 66, 13, 95, 37, 82, 31, 71, 56, 72, 53, 89, 42, 81, 43, 80, 59, 65, 48, 86, 28, 69, 27, 94, 58, 82, 20, 98, 56, 66, 26, 76, 50, 74, 61, 68, 43, 67, 62, 65, 52, 98, 63, 85, 61, 73, 61, 67, 64, 94, 44, 85, 45, 72, 16, 95, 14, 75, 34, 87, 30, 96, 23, 81, 62, 65, 44, 85, 20, 68, 55, 92, 61, 90, 33, 94, 14, 67, 33, 86, 42, 76, 47, 65, 37, 98, 30, 71, 43, 84, 32, 91, 36, 77, 24, 68, 23, 89, 35, 84, 62, 81, 18, 98, 33, 99, 46, 92, 52, 85, 29, 81, 19, 93, 64, 97, 16, 90, 26, 92, 44, 79, 47, 93, 21, 87, 49, 72, 46, 95, 46, 71, 55, 94, 25, 93, 53, 95, 37, 77, 20, 68, 44, 100, 42, 74, 25, 86, 58, 92, 64, 80, 60, 85, 40, 78, 54, 90, 23, 80, 44, 73, 29, 82, 19, 88, 31, 67, 18, 91, 62, 84, 35, 74, 61, 82, 21, 77, 38, 86, 21, 100, 56, 68, 34, 86, 36, 67, 57, 100, 29, 97, 47, 77, 46, 89, 29, 97, 16, 71, 55, 82, 63, 83, 48, 71, 50, 86, 55, 67, 40, 84, 18, 73, 25, 94, 45, 79, 19, 97, 13, 93, 57, 73, 60, 100, 38, 80, 22, 82, 40, 65, 60, 79, 31, 91, 23, 91, 17, 97, 36, 100, 40, 96, 18, 95, 56, 94, 30, 95, 51, 68, 52, 66, 30, 88, 22, 83, 37, 90, 49, 73, 47, 73, 14, 97, 56, 95, 38, 75, 21, 87, 33, 89, 21, 71, 44, 73, 36, 96, 31, 66, 32, 76, 45, 79, 49, 99, 54, 79, 43, 75, 55, 77, 44, 65, 17, 75, 17, 80, 57, 99, 14, 89, 15, 70, 59, 77, 57, 71, 23, 68, 58, 94, 57, 67, 54, 69, 44, 88, 22, 69, 27, 89, 25, 82, 62, 79, 14, 94, 14, 98, 61, 79, 41, 74, 42, 79, 58, 69, 13, 98, 59, 92, 62, 83, 39, 94, 19, 77, 60, 81, 64, 73, 46, 66, 23, 85, 38, 92, 19, 83, 50, 68, 43, 79, 49, 84, 39, 85, 41, 98, 15, 87, 61, 92, 25, 90, 50, 84, 55, 71, 18, 98, 63, 70, 24, 86, 28, 96, 50, 87, 28, 70, 52, 78, 24, 95, 45, 91, 49, 100, 38, 80, 36, 84, 38, 74, 56, 73, 24, 97, 38, 95, 60, 68, 42, 85, 24, 92, 27, 95, 55, 71, 18, 67, 32, 81, 21, 79, 38, 89, 18, 72, 43, 95, 60, 99, 49, 79, 63, 100, 47, 97, 37, 94, 13, 81, 19, 92, 20, 87, 33, 65, 40, 71, 41, 79, 29, 72, 31, 96, 28, 82, 50, 88, 31, 92, 59, 99, 16, 70, 60, 87, 24, 85, 14, 96, 36, 80, 57, 71, 56, 73, 64, 83, 57, 75, 40, 99, 42, 83, 39, 97, 17, 93, 54, 75, 51, 79, 19, 98, 42, 72, 57, 96, 40, 98, 29, 79, 19, 95, 27, 65, 56, 68, 46, 79, 28, 96, 51, 95, 60, 72, 47, 82, 16, 80, 26, 82, 59, 66, 52, 100, 58, 87, 42, 74, 39, 71, 17, 99, 61, 90, 40, 79, 18, 82, 30, 76, 31, 84, 64, 78, 47, 71, 47, 88, 60, 75, 33, 90, 49, 65, 62, 71, 17, 87, 15, 71, 63, 92, 51, 93, 39, 85, 53, 85, 63, 92, 51, 69, 27, 66, 40, 86, 50, 80, 25, 91, 53, 87, 46, 66, 52, 99, 17, 70, 57, 74, 37, 73, 16, 70, 58, 87, 45, 84, 35, 77, 35, 73, 47, 79, 32, 96, 63, 67, 57, 93, 49, 98, 54, 92, 60, 73, 61, 68, 31, 86, 26, 77, 55, 70, 34, 96, 62, 98, 15, 69, 60, 85, 54, 82, 41, 70, 54, 85, 28, 81, 15, 98, 49, 88, 52, 90, 34, 99, 28, 100, 19, 87, 21, 88, 20, 97, 26, 83, 21, 85, 58, 86, 46, 89, 23, 67, 47, 71, 23, 92, 36, 89, 44, 72, 55, 79, 47, 95, 44, 77, 48, 75, 42, 67, 63, 80, 31, 69, 44, 65, 28, 92, 40, 82, 43, 89, 61, 70, 22, 93, 20, 88, 64, 78, 22, 90, 55, 83, 55, 96, 43, 68, 61, 93, 14, 93, 26, 88, 43, 81, 41, 95, 40, 100, 22, 75, 58, 74, 57, 94, 58, 88, 13, 83, 53, 79, 58, 84, 20, 81, 32, 94, 38, 91, 31, 70, 23, 81, 63, 80, 37, 100, 46, 67, 31, 91, 32, 80, 26, 71, 56, 81, 40, 87, 25, 84, 19, 96, 50, 77, 24, 85, 53, 79, 20, 80, 22, 85, 61, 76, 27, 78, 26, 90, 49, 72, 16, 85, 24, 83, 15, 72, 56, 96, 33, 88, 15, 80, 40, 77, 36, 73, 62, 90, 35, 99, 24, 90, 25, 80, 31, 79, 28, 78, 47, 83, 49, 97, 21, 95, 27, 70, 19, 75, 47, 93, 21, 94, 14, 97, 41, 75, 46, 98, 35, 92, 51, 76, 19, 93, 29, 91, 51, 74, 54, 91, 29, 91, 24, 89, 64, 68, 40, 75, 20, 87, 18, 91, 38, 81, 17, 70, 34, 74, 48, 65, 15, 86, 16, 100, 47, 93, 16, 81, 30, 70, 16, 68, 14, 77, 60, 79, 33, 97, 40, 80, 14, 76, 43, 79, 14, 88, 55, 93, 64, 69, 64, 74, 50, 69, 59, 77, 55, 98, 48, 69, 24, 95, 21, 97, 62, 68, 18, 99, 60, 84, 47, 98, 63, 78, 49, 78, 28, 66, 37, 82, 55, 87, 44, 75, 27, 90, 43, 98, 46, 67, 22, 66, 35, 99, 13, 67, 52, 84, 17, 96, 40, 81, 17, 65, 50, 79, 27, 97, 43, 90, 29, 96, 44, 69, 61, 98, 59, 97, 45, 84, 42, 84, 20, 67, 51, 92, 54, 95, 55, 90, 63, 65, 55, 79, 27, 84, 55, 74, 38, 83, 39, 99] [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_sample,train_lablel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As keras expects data in numpy array\n",
    "train_sample=np.array(train_sample)\n",
    "train_label=np.array(train_lablel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 82 39 ... 83 39 99]\n"
     ]
    }
   ],
   "source": [
    "print(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[24. 82. 39. ... 83. 39. 99.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fe2eb86ac4f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscaler_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    351\u001b[0m         X = check_array(X, copy=self.copy,\n\u001b[0;32m    352\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[24. 82. 39. ... 83. 39. 99.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "scaler=MinMaxScaler(feature_range=(0,1))#MInmax scalar is used to change the irregular values in train_sample to 0's and 1's\n",
    "scaler_train=scaler.fit_transform(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler(feature_range=(0,1))#MInmax scalar is used to change the irregular values in train_sample to 0's and 1's\n",
    "scaler_train=scaler.fit_transform(train_sample.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12643678]\n",
      " [0.79310345]\n",
      " [0.29885057]\n",
      " ...\n",
      " [0.8045977 ]\n",
      " [0.29885057]\n",
      " [0.98850575]]\n",
      "(2000, 1)\n",
      "(2000,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(scaler_train)\n",
    "print(scaler_train.shape)\n",
    "print(train_label.shape)\n",
    "print(train_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential#Responsible to create sequence of Ops\n",
    "from keras.layers import Dense,Activation,Embedding,Flatten,BatchNormalization\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU,ELU,ReLU\n",
    "from keras.activations import relu,sigmoid\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model (layers,activation):\n",
    "    model=Sequential()\n",
    "    for i, nodes in enumerate(layers):\n",
    "        if i==0:\n",
    "            model.add(Dense(nodes,input_dim=scaler_train.shape[1]))#INput layer\n",
    "            model.add(Activation(activation))\n",
    "            model.add(Dropout(0.3))\n",
    "        else:\n",
    "            model.add(Dense(nodes))#Creating hidden layer with neurons\n",
    "            model.add(Activation(activation))\n",
    "            model.add(Dropout(0.3))\n",
    "            \n",
    "    model.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))#Output neuron\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model          \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KerasClassifier(build_fn=create_model,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=[[20],[30,15],[40,35,20]]\n",
    "activations=['relu','sigmoid']\n",
    "hyper_param_grid=dict(layers=layers,activation=activations,batch_size=[10],epochs=[12])\n",
    "grid=GridSearchCV(estimator=model,param_grid=hyper_param_grid,cv=5)\n",
    "#grid_result=grid.fit(scaler_train,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0830 15:37:44.075392 13968 deprecation_wrapper.py:119] From C:\\Users\\3idiots\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0830 15:37:44.077064 13968 deprecation_wrapper.py:119] From C:\\Users\\3idiots\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0830 15:37:44.099008 13968 deprecation.py:506] From C:\\Users\\3idiots\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0830 15:37:44.261749 13968 deprecation.py:323] From C:\\Users\\3idiots\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0830 15:37:45.025354 13968 deprecation_wrapper.py:119] From C:\\Users\\3idiots\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "W0830 15:37:45.592617 13968 deprecation_wrapper.py:119] From C:\\Users\\3idiots\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0830 15:37:45.623536 13968 deprecation_wrapper.py:119] From C:\\Users\\3idiots\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_result=grid.fit(train_sample,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9729999959468841 {'activation': 'sigmoid', 'batch_size': 10, 'epochs': 12, 'layers': [40, 35, 20]}\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_score_,grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating test sample and model\n",
    "test_sample=[]# Will have list of peoples who have been provided with vaccination or not\n",
    "test_lablel=[]#Vaccination provide has any side affect or not\n",
    "\n",
    "for i in range(400):\n",
    "    age_young=randint(13,64)\n",
    "    test_sample.append(age_young)\n",
    "    test_lablel.append(0)\n",
    "    \n",
    "    age_older=randint(65,100)\n",
    "    test_sample.append(age_older)\n",
    "    test_lablel.append(1)\n",
    "    \n",
    "test_sample=np.array(test_sample)\n",
    "test_label=np.array(test_lablel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'predict_classess'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-763b7380668f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'predict_classess'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model.predict_classess(test_sample,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 34,  90,  63,  79,  58,  78,  46,  82,  16, 100,  17,  81,  64,\n",
       "        84,  48,  97,  47,  79,  64,  71,  14,  93,  60,  81,  17,  72,\n",
       "        53,  68,  31,  88,  54,  83,  16,  89,  51,  93,  35,  82,  55,\n",
       "        76,  50,  96,  54,  65,  18,  89,  43,  88,  29,  66,  37,  94,\n",
       "        26,  95,  47,  69,  57,  74,  39,  65,  20,  87,  60,  96,  24,\n",
       "        67,  41,  93,  26,  90,  43,  79,  29,  80,  59,  67,  40,  77,\n",
       "        35,  74,  33,  79,  55,  75,  40,  73,  45,  73,  29,  79,  31,\n",
       "        90,  35, 100,  32,  91,  17,  73,  48,  88,  55,  73,  55,  92,\n",
       "        36,  93,  37,  76,  62,  87,  49,  92,  16,  92,  14,  79,  60,\n",
       "        82,  29,  72,  54,  88,  20,  79,  31,  93,  45,  69,  33,  76,\n",
       "        30,  77,  23,  89,  35,  84,  59,  69,  56,  85,  25,  85,  50,\n",
       "        65,  64,  72,  26,  73,  57,  84,  18,  89,  15,  88,  57,  98,\n",
       "        50,  86,  51,  82,  47,  74,  21,  91,  42,  78,  20,  96,  20,\n",
       "        68,  36,  93,  53,  72,  38,  65,  37,  85,  34,  98,  37,  73,\n",
       "        62,  90,  52,  89,  32,  69,  18,  94,  39,  83,  60,  86,  15,\n",
       "        69,  19,  91,  32,  76,  64,  65,  56,  73,  27,  85,  62,  84,\n",
       "        18,  96,  25,  92,  45,  73,  43,  99,  54,  75,  34,  99,  47,\n",
       "        92,  36,  92,  34,  99,  43,  96,  45,  67,  15,  67,  33,  73,\n",
       "        51,  69,  37,  66,  18,  68,  53,  91,  35, 100,  49,  68,  15,\n",
       "        95,  26,  67,  14,  86,  19,  85,  18,  82,  35,  74,  17,  65,\n",
       "        62,  67,  55,  78,  33,  68,  25, 100,  44,  83,  30,  72,  48,\n",
       "        72,  19,  74,  17, 100,  63,  67,  44,  94,  16,  74,  32,  89,\n",
       "        51,  69,  39,  79,  54,  78,  34,  83,  59,  98,  43,  86,  19,\n",
       "        94,  19,  71,  23,  81,  35,  66,  56,  88,  28,  86,  22,  66,\n",
       "        49,  71,  47,  87,  18,  67,  37,  96,  41,  73,  14,  79,  54,\n",
       "        90,  58,  83,  22,  72,  45,  66,  40,  76,  21,  98,  30,  84,\n",
       "        40,  87,  51,  68,  42,  90,  50,  85,  35,  86,  18,  91,  51,\n",
       "        86,  44,  86,  19,  82,  28,  89,  63,  68,  14,  79,  46,  67,\n",
       "        33, 100,  19,  65,  45,  85,  50,  88,  34,  97,  62,  90,  25,\n",
       "        81,  35,  99,  48,  96,  15,  90,  17,  71,  53,  72,  40, 100,\n",
       "        37,  71,  33,  69,  18,  77,  36,  84,  64,  87,  61,  78,  62,\n",
       "        96,  62,  86,  33,  66,  55,  88,  57,  76,  36,  79,  54,  78,\n",
       "        22,  68,  53,  74,  47,  95,  43,  80,  26,  95,  44,  78,  63,\n",
       "        78,  56,  65,  27, 100,  36,  80,  16,  69,  26, 100,  28,  68,\n",
       "        34,  89,  23,  69,  25,  83,  34,  98,  43,  68,  47,  77,  18,\n",
       "        78,  60,  66,  15,  96,  15,  94,  38,  69,  14,  95,  62,  97,\n",
       "        59,  77,  48,  71,  27,  86,  16,  97,  46,  70,  35,  82,  46,\n",
       "        93,  31,  80,  22,  66,  22,  84,  46,  70,  48,  69,  34,  66,\n",
       "        19,  81,  15,  95,  21,  91,  26,  77,  33,  99,  61,  91,  55,\n",
       "        84,  56,  90,  64,  69,  35,  96,  52,  94,  34,  76,  23,  72,\n",
       "        27,  89,  48,  94,  47,  84,  21,  84,  30,  98,  50,  81,  52,\n",
       "        91,  20,  89,  62,  81,  36,  96,  30,  87,  45,  78,  30,  77,\n",
       "        19,  68,  35,  93,  47,  91,  61,  91,  62,  89,  56,  68,  53,\n",
       "        71,  21,  87,  25,  67,  50,  82,  31,  84,  20,  97,  34,  73,\n",
       "        53,  70,  17,  67,  49,  67,  55,  84,  20,  80,  57,  89,  13,\n",
       "        95,  38,  68,  59,  72,  34,  96,  40,  93,  47,  99,  24,  69,\n",
       "        23,  65,  17,  99,  13,  84,  37,  78,  23,  70,  15,  94,  45,\n",
       "        70,  48,  65,  54,  80,  47,  75,  34,  80,  60,  96,  36,  78,\n",
       "        26,  83,  37,  79,  29,  85,  15,  92,  26,  71,  44,  99,  23,\n",
       "        72,  64,  95,  15,  89,  14,  81,  25,  83,  15,  83,  14,  93,\n",
       "        40,  82,  57,  98,  37,  92,  39,  96,  30,  80,  15,  80,  64,\n",
       "        85,  47,  76,  61,  84,  54,  79,  60,  89,  21,  92,  62,  65,\n",
       "        21,  90,  38,  99,  16,  82,  18,  97,  57,  85,  60,  89,  44,\n",
       "        76,  30,  73,  38,  65,  14,  87,  17,  70,  40,  83,  58,  69,\n",
       "        16,  78,  51,  90,  36,  78,  52,  86,  15,  81,  35,  73,  37,\n",
       "        88,  25,  89,  47,  77,  46,  85,  59,  88,  63,  90,  18,  89,\n",
       "        64,  71,  15,  94,  50,  84,  56,  75,  16,  87,  18,  65,  27,\n",
       "        77,  31,  78,  20,  88,  13,  76,  34,  73,  45,  93,  23,  67,\n",
       "        21,  87,  25,  69,  18,  69,  14,  84,  58,  89,  57,  94,  24,\n",
       "        94,  42,  93,  53,  83,  32,  92,  13,  93,  63,  65,  47,  82,\n",
       "        16,  99,  27,  91,  50,  96,  21,  75,  19,  69,  61,  83,  26,\n",
       "        86,  54,  74,  34,  90,  32,  70])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=grid.predict(test_sample)\n",
    "y_pred=(y_pred>0.5)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking through Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_pred,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[400,  14],\n",
       "       [  0, 386]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9825\n"
     ]
    }
   ],
   "source": [
    "#To check the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(test_label,y_pred)\n",
    "print('The accuracy is',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
